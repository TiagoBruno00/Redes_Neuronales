# Autoencoders y Clasificadores Convolucionales sobre Fashion-MNIST

An√°lisis experimental de arquitecturas de Redes Neuronales y la **Optimizaci√≥n de Hiperpar√°metros** para tareas de reconstrucci√≥n y clasificaci√≥n de im√°genes.

## Resumen

Este proyecto implementa y compara distintos tipos de **Autoencoders** (Lineal y Convolucionales) y **Clasificadores** sobre el conjunto de datos **Fashion-MNIST**. El objetivo principal es reflexionar sobre la elecci√≥n de **hiperpar√°metros** (√©pocas, tama√±o de lote, tasa de aprendizaje, dropout) y su impacto en el rendimiento.

### üéØ Conclusiones Clave

* **Superioridad Convolucional:** Las Redes Convolucionales demostraron ser **superiores** a las *feed-forward* (Lineales) para este conjunto de datos, tanto para comprimir y reconstruir im√°genes como para clasificarlas.
* **Reconstrucci√≥n (Autoencoders):** Aumentar el tama√±o de la capa oculta mejor√≥ la reconstrucci√≥n. El modelo **Raschka (n=128)** alcanz√≥ un error comparable al Lineal (n=512) pero en solo **14 √©pocas** (vs. 60 √©pocas).
* **Optimizaci√≥n por Arquitectura:** La elecci√≥n de hiperpar√°metros depende del tipo de red:
    * **Redes Convolucionales** (Consigna, Raschka) aprendieron mejor con **lotes peque√±os (32)** y tasas de aprendizaje **bajas (0.0005)**.
    * **Redes Lineales** (*Feed-Forward*) funcionaron mejor con **lotes grandes (1000)** y tasas de aprendizaje **altas (0.001)**.
* **Estrategias de Regularizaci√≥n:** El *Dropout* fue m√°s efectivo en la red Lineal, mientras que el *Pooling* ayud√≥ a la generalizaci√≥n en las convolucionales.
* **Clasificaci√≥n:** Se aplic√≥ **Feature Extraction** (Transfer Learning) sobre el clasificador "Consigna" para mitigar la dependencia de valores iniciales, obteniendo mejores resultados.

## üõ†Ô∏è Modelos Implementados

| Modelo | Tipo | Capa Oculta | √âpocas | Tasa de Aprendizaje | Dropout |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Autoencoder Lineal** | Feed-Forward | 512 | 60 | 0.001 | 0.1 |
| **Autoencoder Raschka** | Convolucional | 128 | 14 | 0.0005 | 0 |
| **Clasificador Consigna FE** | Convolucional | 128 | 26 | 0.0005 | 0.8 |

## üìÅ Estructura del Repositorio

* `Tiago_Bruno_tfi_2023.pdf` (trabajo completo)
* `autoencoder_lineal.py`
* `autoencoder_consigna.py`
* `autoencoder_raschka.py`
* `clasificador.py`

